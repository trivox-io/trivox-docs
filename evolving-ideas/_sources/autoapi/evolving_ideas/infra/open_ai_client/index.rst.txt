evolving_ideas.infra.open_ai_client
===================================

.. py:module:: evolving_ideas.infra.open_ai_client

.. autoapi-nested-parse::

   evolving_ideas.infra.open_ai_client



Attributes
----------

.. autoapisummary::

   evolving_ideas.infra.open_ai_client.logger
   evolving_ideas.infra.open_ai_client.cache


Exceptions
----------

.. autoapisummary::

   evolving_ideas.infra.open_ai_client.OpenAIClientError


Classes
-------

.. autoapisummary::

   evolving_ideas.infra.open_ai_client.OpenAITransport
   evolving_ideas.infra.open_ai_client.OpenAICredentialValidator
   evolving_ideas.infra.open_ai_client.OpenAILLM


Functions
---------

.. autoapisummary::

   evolving_ideas.infra.open_ai_client.cached_validation_wrapper


Module Contents
---------------

.. py:data:: logger

.. py:data:: cache

.. py:exception:: OpenAIClientError

   Bases: :py:obj:`Exception`


   Custom exception for OpenAI client errors.


.. py:class:: OpenAITransport(api_key: Optional[str] = None)

   OpenAI client for interacting with the OpenAI API.


   .. py:attribute:: client


   .. py:method:: get_models() -> dict

      # Get the available models from OpenAI.

      :return: A dictionary categorizing available models.
      :rtype: dict



   .. py:method:: chat_completion(model: str, messages: list, temperature: float = 0.7) -> dict

      Chat completion using the OpenAI API.

      :param model: The model to use (e.g., "gpt-4").
      :type model: str

      :param messages: The messages to send to the model.
      :type messages: list

      :param temperature: The temperature for the model (default is 0.7).
      :type temperature: float

      :return: The response from the model.
      :rtype: dict



   .. py:method:: create_thread()
      :abstractmethod:


      Create a new thread for the OpenAI API.



   .. py:method:: run_thread(assistant_id: str, thread_id: str)
      :abstractmethod:


      Run a thread for the OpenAI API.

      :param assistant_id: The ID of the assistant.
      :type assistant_id: str

      :param thread_id: The ID of the thread.
      :type thread_id: str



   .. py:method:: add_message(thread_id: str, role: str, content: str)
      :abstractmethod:


      Add a message to a thread.

      :param thread_id: The ID of the thread.
      :type thread_id: str

      :param role: The role of the message sender (e.g., "user", "assistant").
      :type role: str

      :param content: The content of the message.
      :type content: str



   .. py:method:: get_messages(thread_id: str)
      :abstractmethod:


      Get messages from a thread.

      :param thread_id: The ID of the thread.
      :type thread_id: str



.. py:function:: cached_validation_wrapper(key: str = 'valid_api_key')

   Decorator to check for a cached validation flag before executing a function.

   :param key: Key in the cached file to verify.


.. py:class:: OpenAICredentialValidator(client: openai.OpenAI)

   Validates OpenAI API credentials.


   .. py:attribute:: client


   .. py:method:: validate() -> bool

      Validate the OpenAI API key.

      :return: True if the API key is valid, False otherwise.
      :rtype: bool

      :raises OpenAIClientError: If the API key is invalid.



.. py:class:: OpenAILLM(model='gpt-4.1', transport: Optional[OpenAITransport] = None, **kwargs)

   OpenAI Language Model Wrapper


   .. py:attribute:: name
      :type:  str
      :value: 'openai'



   .. py:attribute:: model
      :value: 'gpt-4.1'



   .. py:attribute:: transport
      :value: None



   .. py:method:: ask(prompt: str, context: Optional[str] = 'You are a helpful assistant.') -> str

      Ask the OpenAI model a question and return the answer.

      :param prompt: The question to ask.
      :type prompt: str

      :param role: The role of the user (e.g., "user", "assistant").
      :type role: str

      :param content: The content of the message.
      :type content: str

      :return: The answer from the model.
      :rtype: str



   .. py:method:: chat(chatlog: list[dict]) -> str

      Chat with the OpenAI model using a chat log.

      :param chatlog: The chat log to send to the model.
      :type chatlog: list[dict]

      :return: The response from the model.
      :ytype: str



